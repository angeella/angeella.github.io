---
title: ""
output: 
  html_document:
    toc: FALSE
---

# <span style="color:red"> FOREST FIRES IN BRAZIL </span>

See <https://www.kaggle.com/gustavomodelli/forest-fires-in-brazil> for a full description of the dataset.

Import packages

```{python}
import pandas as pd #Handle datasets
import seaborn as sns #Plots
import matplotlib.pyplot as plt  #Plots
import matplotlib

#Set some graphical parameters
rc={'axes.labelsize': 25, 'figure.figsize': (20,10), 
    'axes.titlesize': 25, 'xtick.labelsize': 18, 'ytick.labelsize': 18}
sns.set(rc=rc)

#Path data
path = 'C:/Users/Andreella/Documents/GitHub/angeella.github.io/Data'
df = pd.read_csv(path + '/amazon.csv',encoding="ISO-8859-1")
```

First $3$ observations:


```{python}
df.head(n=3)
```
Some **information** about the variables:


```{python}
df.info() 
```



We are interested about the **number of forest fires** in Brazil


```{python}
df.number.describe()
```


To have an simple plot, we take a subset of the dataset:


```{python}
df1 = df[(df.year > 2010) & (df.year < 2019)]
df1 =df1.loc[(df1.state.str.startswith('M'))]
```

We do a **boxplot** about the number of fire by groups, i.e., the **states** and the **years**.


```{python}
sns.boxplot(x = 'year', y = 'number', hue = "state", data = df1) 
```


We do a **timeseries plot with error bands**:


```{python}
sns.lineplot(x="year", y="number",hue="state", data=df1)

```


also we do a **grouped violinplots**:


```{python}
sns.violinplot(x="state", y="number", data=df1)  
```

For other plots, please refers to <https://seaborn.pydata.org/examples/index.html>.

# <span style="color:red"> ECONOMIC FREEDOM INDEX</span>

See <https://www.kaggle.com/lewisduncan93/the-economic-freedom-index> for a full description of the dataset.

Load and preprocess data


```{python}
dt = pd.read_csv(path + '/economic_freedom_index2019_data.csv',encoding="ISO-8859-1")
dt.columns = dt.columns.str.replace(' ', '')
dt.columns = dt.columns.str.replace('2019', '')
dt.columns = dt.columns.str.replace('%', '')
dt.columns = dt.columns.str.replace('(', '')
dt.columns = dt.columns.str.replace(')', '')
dt = dt.dropna(axis = 0,how='any')
```

Basic info 

```{python}
dt.info()
```


## <span style="color:blue"> Some plots </span>

Boxplot by group, i.e. **region**:


```{python}
sns.boxplot(x = 'Region', y = 'Score', data = dt) 
```


First **scatter plot**:


```{python}
plt.scatter(x="PropertyRights", y="Score", data=dt)
```




We can put directly the **linear regression fitting**:


```{python}
sns.lmplot(x="PropertyRights", y="Score", data=dt)
```




Density plot of the **score** variable:


```{python}
sns.distplot(dt.Score, color="r")
```




**Pair plot** considering some variables, i.e. Property Rights, Labor Freedom, Government Integrity, Judical Effectiveness, Fiscal Health, Region and Score:


```{python}
dt1 = dt[['PropertyRights', 'LaborFreedom', 'GovernmentIntegrity', 'JudicalEffectiveness','FiscalHealth', "Score", 'Region']]
```


```{python}
matplotlib.rc_file_defaults()
sns.pairplot(dt1, hue="Region")
```





# <span style="color:blue"> Linear regression </span>

Import packages 


```{python}
import statsmodels.api as sm
import statsmodels.formula.api as smf
from sklearn.metrics import mean_squared_error
import sklearn
```

Correlation matrix


```{python}
corr = dt[['PropertyRights', 'LaborFreedom', 'GovernmentIntegrity', 'JudicalEffectiveness','FiscalHealth', "Score"]].corr()
corr
```


Heatmap of the **correlation matrix**:


```{python}
sns.heatmap(corr, 
        xticklabels=corr.columns,
        yticklabels=corr.columns)
```



We split the dataset into training (0.8) and test set (0.2):


```{python}
import numpy as np
msk = np.random.rand(len(dt)) < 0.8
train = dt[msk]
test = dt[~msk]
```

**Linear regression** having as dependent variable the **Score** and PropertyRights, LaborFreedom and FiscalHealth as explicative variables:


```{python}
results = smf.ols('Score ~ PropertyRights + LaborFreedom + FiscalHealth', data=train).fit()
results.summary()
```




We **predict** the score values using the test set:


```{python}
pred = results.predict(test)
plt.scatter(test.Score, pred,  color='b')
```


Compute the **mean squared error**:


```{python}
mean_squared_error(test.Score, pred)
```


We try to use a **linear mixed model**, considering as random effects the Region variable.


```{python}
md = smf.mixedlm("Score ~ PropertyRights + LaborFreedom + FiscalHealth", train, groups="Region")
mdf = md.fit()
mdf.summary()
```





See <http://www.statsmodels.org/stable/index.html> for other commands about the linear (mixed) model. Also, <https://www.statsmodels.org/stable/examples/notebooks/generated/mixed_lm_example.html> makes a comparison between R lmer and Statsmodels MixedLM.

# <span style="color:blue"> Principal Component Analysis </span>

Import packages:


```{python}
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import numpy as np
```

Standardize data:


```{python}
features = ['PropertyRights', 'LaborFreedom', 'GovernmentIntegrity', 'JudicalEffectiveness','FiscalHealth']
# Separating out the features
x = dt.loc[:, features].values
# Separating out the target
y = dt.loc[:,'Score'].values
# Standardizing the features
x = StandardScaler().fit_transform(x)
```

Perform PCA considering $2$ principal components:


```{python}
pca = PCA(4)
projected = pca.fit_transform(x)
```


```{python}
print(x.shape)
print(projected.shape)
```



Plot the first $2$ principal components:


```{python}
plt.scatter(projected[:, 0], projected[:, 1],
            c=y, edgecolor='none', alpha=0.5,
            cmap=plt.cm.get_cmap('seismic', 10))
plt.xlabel('component 1')
plt.ylabel('component 2')
plt.colorbar()
```



```{python}
plt.plot(np.cumsum(pca.explained_variance_ratio_)) 
plt.xlabel("Number of component") 
plt.ylabel("Variance explained")
plt.xticks(range(4), [1,2,3,4])
```

